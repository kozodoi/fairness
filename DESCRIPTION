Package: fairness
Title: Algorithmic Fairness Metrics
Version: 1.1.0.900
Authors@R: c(person('Nikita', 'Kozodoi', email = 'nikita.kozodoi@hu-berlin.de', role = c('aut', 'cre')),
            person('Tibor', 'V. Varga', email = 'tirgit@hotmail.com', role = c('aut'), comment = c(ORCID = '0000-0002-2383-699X')))
Maintainer: Nikita Kozodoi <nikita.kozodoi@hu-berlin.de>
Description: Offers various metrics of algorithmic fairness. Fairness in machine learning is an emerging topic with the overarching aim to critically assess algorithms (predictive and classification models) whether their results reinforce existing social biases. While unfair algorithms can propagate such biases and offer prediction or classification results with a disparate impact on various sensitive subgroups of populations (defined by sex, gender, ethnicity, religion, income, socioeconomic status, physical or mental disabilities), fair algorithms possess the underlying foundation that these groups should be treated similarly / should have similar outcomes. The fairness R package offers the calculation and comparisons of commonly and less commonly used fairness metrics in population subgroups. These methods are described by Calders and Verwer (2010) <doi:10.1007/s10618-010-0190-x>, Chouldechova (2017) <doi:10.1089/big.2016.0047>, Feldman et al. (2015) <doi:10.1145/2783258.2783311> , Friedler et al. (2018) <doi:10.1145/3287560.3287589> and Zafar et al. (2017) <doi:10.1145/3038912.3052660>. The package also offers convenient visualizations to help understand fairness metrics.
License: MIT + file LICENSE
Encoding: UTF-8
LazyData: true
RoxygenNote: 7.1.0
BugReports: https://github.com/kozodoi/fairness/issues
Depends: R (>= 3.5.0)
Imports:
    caret,
    devtools,
    e1071,
    ggplot2,
    pROC
Suggests: 
    testthat,
    knitr,
    rmarkdown
VignetteBuilder: knitr
